{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..')))\n",
    "import timm\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "from torchprofile import profile_macs\n",
    "from torch.profiler import profile, record_function, ProfilerActivity\n",
    "import numpy as np\n",
    "import json\n",
    "from PIL import Image\n",
    "os.environ['HF_HUB_DISABLE_SYMLINKS_WARNING'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelAnalyzer:\n",
    "    def __init__(self, model_name, pretrained=True, device='cuda'):\n",
    "        self.device = 'cuda' if torch.cuda.is_available() and device == 'cuda' else 'cpu'\n",
    "        self.model = timm.create_model(model_name, pretrained=pretrained)\n",
    "        self.model_name = model_name\n",
    "        self.model.to(self.device)\n",
    "        self.model.eval()\n",
    "        \n",
    "    def prepare_input(self, batch_size=1):\n",
    "        input_size = self.model.default_cfg['input_size']\n",
    "        dummy_input = torch.randn(batch_size, *input_size).to(self.device)\n",
    "        return dummy_input\n",
    "    \n",
    "    def get_model_profile(self, input_tensor):\n",
    "        macs = profile_macs(self.model, (input_tensor,))\n",
    "        params = sum(p.numel() for p in self.model.parameters())\n",
    "        return {'MACs': macs}, {'Params': params}\n",
    "    \n",
    "    def profile_model(self, input_tensor):\n",
    "        with profile(activities=[ProfilerActivity.CPU, ProfilerActivity.CUDA], record_shapes=True) as prof:\n",
    "            with record_function(\"model_inference\"):\n",
    "                with torch.no_grad():\n",
    "                    _ = self.model(input_tensor)\n",
    "        return prof\n",
    "    \n",
    "    # def parse_profiling(self, prof):\n",
    "    #     # Convert the profiling data into a structured format\n",
    "    #     prof_data = []\n",
    "    #     for event in prof.key_averages():\n",
    "    #         event_data = {'Name': event.key}\n",
    "    #         # Loop through all attributes of the event\n",
    "    #         for attr in dir(event):\n",
    "    #             # Filter out private and callable attributes\n",
    "    #             if not attr.startswith('_') and not callable(getattr(event, attr)):\n",
    "    #                 value = getattr(event, attr)\n",
    "    #                 # Ensure the value is JSON serializable\n",
    "    #                 try:\n",
    "    #                     json.dumps(value)  # Test if value is JSON serializable\n",
    "    #                     event_data[attr] = value\n",
    "    #                 except (TypeError, OverflowError):\n",
    "    #                     event_data[attr] = str(value)  # Convert non-serializable types to string\n",
    "    #         prof_data.append(event_data)\n",
    "    #     return prof_data\n",
    "    \n",
    "    def parse_profiling(self, prof):\n",
    "        # Convert the profiling data into a structured format\n",
    "        prof_data = []\n",
    "        for event in prof.key_averages():\n",
    "            event_data = {'Name': event.key}\n",
    "            # Loop through all attributes of the event\n",
    "            for attr in dir(event):\n",
    "                # Skip 'cpu_children' and filter out private and callable attributes\n",
    "                if attr == 'cpu_children' or attr.startswith('_') or callable(getattr(event, attr)):\n",
    "                    continue\n",
    "                value = getattr(event, attr)\n",
    "                # Ensure the value is JSON serializable\n",
    "                try:\n",
    "                    json.dumps(value)  # Test if value is JSON serializable\n",
    "                    event_data[attr] = value\n",
    "                except (TypeError, OverflowError):\n",
    "                    event_data[attr] = str(value)  # Convert non-serializable types to string\n",
    "            prof_data.append(event_data)\n",
    "        return prof_data\n",
    "\n",
    "    def generate_report(self, prof_data, model_profile, layer_times):\n",
    "        report = {\n",
    "            'ModelProfile': model_profile,\n",
    "            'LayerWiseProfiling': prof_data,\n",
    "            'LayerExecutionTimes': layer_times\n",
    "        }\n",
    "        report_json = json.dumps(report, indent=4)\n",
    "        with open(f'{self.model_name}_report.json', 'w') as f:\n",
    "            f.write(report_json)\n",
    "        return report_json\n",
    "    \n",
    "    # Hooks\n",
    "    def add_hooks(self):\n",
    "        self.hooks = []\n",
    "        for name, module in self.model.named_modules():\n",
    "            hook = module.register_forward_hook(self.get_hook(name))\n",
    "            self.hooks.append(hook)\n",
    "        self.layer_times = {}\n",
    "\n",
    "    def get_hook(self, name):\n",
    "        def hook(module, input, output):\n",
    "            start_time = torch.cuda.Event(enable_timing=True)\n",
    "            end_time = torch.cuda.Event(enable_timing=True)\n",
    "            start_time.record()\n",
    "            # Forward pass\n",
    "            end_time.record()\n",
    "            torch.cuda.synchronize()\n",
    "            elapsed_time = start_time.elapsed_time(end_time)\n",
    "            self.layer_times[name] = elapsed_time\n",
    "        return hook\n",
    "\n",
    "    def remove_hooks(self):\n",
    "        for hook in self.hooks:\n",
    "            hook.remove()\n",
    "            \n",
    "    def profile_model_with_hooks(self, input_tensor):\n",
    "        self.add_hooks()\n",
    "        with torch.no_grad():\n",
    "            _ = self.model(input_tensor)\n",
    "        self.remove_hooks()\n",
    "        return self.layer_times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_12200\\2977959836.py:53: FutureWarning: `cuda_time` is deprecated, please use `device_time` instead.\n",
      "  if attr == 'cpu_children' or attr.startswith('_') or callable(getattr(event, attr)):\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_12200\\2977959836.py:55: FutureWarning: `cuda_time` is deprecated, please use `device_time` instead.\n",
      "  value = getattr(event, attr)\n"
     ]
    }
   ],
   "source": [
    "# Initialize the ModelAnalyzer with a specific model\n",
    "model_name = 'resnet50'  # Example model name\n",
    "analyzer = ModelAnalyzer(model_name=model_name, pretrained=True, device='cuda')\n",
    "\n",
    "# Prepare a dummy input tensor\n",
    "input_tensor = analyzer.prepare_input(batch_size=1)\n",
    "\n",
    "# Get the model profile (MACs and Params)\n",
    "model_profile = analyzer.get_model_profile(input_tensor)\n",
    "# print(\"Model Profile:\", model_profile)\n",
    "\n",
    "# Profile the model using the new torch.profiler\n",
    "prof = analyzer.profile_model(input_tensor)\n",
    "\n",
    "# Parse the profiling data\n",
    "prof_data = analyzer.parse_profiling(prof)\n",
    "# print(\"Profiling Data:\\n\", prof_data)\n",
    "\n",
    "# Optionally, generate a report\n",
    "layer_times = analyzer.profile_model_with_hooks(input_tensor)\n",
    "report = analyzer.generate_report(prof_data, model_profile, layer_times)\n",
    "# print(\"Generated Report:\\n\", report)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
