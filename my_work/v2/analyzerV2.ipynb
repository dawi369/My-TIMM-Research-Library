{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# System libraries\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "from typing import Optional\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..', '..')))\n",
    "\n",
    "# Pytorch/TIMM libraries\n",
    "import timm\n",
    "from timm.models.helpers import model_parameters\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "from torchprofile import profile_macs\n",
    "from torch.profiler import profile, record_function, ProfilerActivity\n",
    "from fvcore.nn import FlopCountAnalysis, parameter_count\n",
    "\n",
    "# Helper libraries\n",
    "import numpy as np\n",
    "import json\n",
    "from PIL import Image\n",
    "from collections import defaultdict\n",
    "\n",
    "# Data visualization\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import ace_tools_open as tools\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "# Environment variables\n",
    "os.environ['HF_HUB_DISABLE_SYMLINKS_WARNING'] = '1'\n",
    "\n",
    "# Commands\n",
    "# tensorboard --logdir=./my_work/v2/logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# models = [model for model in timm.list_models('vit*')]\n",
    "# print([x for x in models if 'vitamin' not in str(x)])\n",
    "model_name = \"vit_base_patch16_224\"\n",
    "\n",
    "#TODO Learn how to use SummaryWriter\n",
    "#TODO Learn what CUDA AMP is\n",
    "#TODO Terrible looking plots in tensorboard, fix\n",
    "#TODO create better plots for layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Analyzer:\n",
    "    def __init__(self, model_name, device=\"cpu\", pretrained=True, pretrained_cfg=None, pretrained_cfg_overlay=None,\n",
    "                checkpoint_path='', scriptable=None, exportable=None, no_jit=True):\n",
    "        self.model_name = model_name\n",
    "        self.device = torch.device(device if torch.cuda.is_available() and device == \"cuda\" else \"cpu\")\n",
    "        print(f\"Using device: {self.device}\")\n",
    "        self.model = timm.create_model(\n",
    "            model_name, pretrained=pretrained, pretrained_cfg=pretrained_cfg, pretrained_cfg_overlay=pretrained_cfg_overlay,\n",
    "            checkpoint_path=checkpoint_path, scriptable=scriptable, exportable=exportable, no_jit=no_jit\n",
    "        ).to(self.device)\n",
    "        self.profiler = None  \n",
    "        \n",
    "        # print(self.model.default_cfg)\n",
    "        # params = sum(p.numel() for p in self.model.parameters())\n",
    "        # print(f\"Number of parameters: {params / 1e6:.2f}M\")\n",
    "    \n",
    "    def inference_one(self, input_tensor: torch.Tensor) -> None:\n",
    "        \"\"\"Run inference on a single input tensor.\"\"\"\n",
    "        input_tensor = input_tensor.to(self.device)\n",
    "        self.model.eval()  \n",
    "        with torch.no_grad():\n",
    "            output = self.model(input_tensor)\n",
    "            print(f\"Model device: {next(self.model.parameters()).device}\")\n",
    "            print(f\"Input tensor device: {input_tensor.device}\")\n",
    "\n",
    "        return output\n",
    "    \n",
    "    def start_profiler(self, create_logfile=False) -> None:\n",
    "        \"\"\"Initialize and start the profiler.\"\"\"\n",
    "        if create_logfile:\n",
    "            trace_handler = torch.profiler.tensorboard_trace_handler('./logs')\n",
    "        else:\n",
    "            trace_handler = None\n",
    "            \n",
    "        self.profiler = profile(\n",
    "            activities=[ProfilerActivity.CPU, ProfilerActivity.CUDA],\n",
    "            on_trace_ready=trace_handler,\n",
    "            record_shapes=True,\n",
    "            with_stack=True,\n",
    "            with_flops=True,\n",
    "            profile_memory=True,\n",
    "            with_modules=True\n",
    "        )\n",
    "        self.profiler.__enter__()  # Start the profiler context manually\n",
    "\n",
    "    def stop_profiler(self) -> None:\n",
    "        \"\"\"Stop the profiler and process the collected data.\"\"\"\n",
    "        if self.profiler:\n",
    "            self.profiler.__exit__(None, None, None) \n",
    "            \n",
    "    def is_cuda_initialized(self, logs=False) -> None:\n",
    "        for name, param in self.model.named_parameters():\n",
    "            if param.device.type != \"cuda\":\n",
    "                if logs:\t\n",
    "                    print(f\"Parameter {name} is not on GPU\")\n",
    "                else:\n",
    "                    print(\"Some or all model parameters are not on GPU\")\n",
    "                    return\n",
    "                # return False\n",
    "        print(\"All model parameters are on the GPU\")\n",
    "        # return True\n",
    "\n",
    "    def list_events(self, show_key_averages=False, list_all=False) -> None:\n",
    "        \"\"\"\n",
    "        List all recorded events from the profiler.\t\n",
    "        name\t         - The name of the operation (e.g., aten::add, aten::matmul, aten::conv2d).\n",
    "\t\tcpu_time_total\t - Total time spent on the CPU for this operation, in microseconds.\n",
    "\t\tcuda_time_total\t - Total time spent on the GPU for this operation, in microseconds.\n",
    "\t\tinput_shapes\t - Shapes of the tensors used as inputs to this operation.\n",
    "\t\toutput_shapes\t - Shapes of the tensors produced by this operation (if applicable).\n",
    "\t\tdevice_type\t     - Whether the operation was executed on CPU or CUDA.\n",
    "\t\tdevice\t         - The device ID on which the operation was executed.\n",
    "\t\tself_cpu_time\t - Time spent on the CPU for this operation alone (excluding time for child operations).\n",
    "\t\tself_cuda_time   - Time spent on the GPU for this operation alone (excluding time for child operations).\n",
    "\t\t\"\"\"\n",
    "        if self.profiler is None:\n",
    "            print(\"Profiler has not been initialized or profiling session has ended.\")\n",
    "        else:\n",
    "            if show_key_averages:\t\n",
    "                print(self.profiler.key_averages().table())\n",
    "            if list_all:\n",
    "                for event in self.profiler.events():\n",
    "                    print(f\"Name: {event.name}, CPU Time: {event.cpu_time_total}, CUDA Time: {event.cuda_time_total}\")\n",
    "    \n",
    "    def event_handler(self, create_csv_file=False, log_to_tensorboard=False, plot_events=False, log_dir='logs') -> Optional[pd.DataFrame]:\n",
    "        if self.profiler is None:\n",
    "            print(\"Profiler has not been initialized or profiling session has ended.\")\n",
    "        else:         \n",
    "            key_averages = self.profiler.key_averages()\n",
    "            \n",
    "            def helper_list_events(key_averages=key_averages):\n",
    "                # Helper code to print all events and their attributes\n",
    "                for i, event in enumerate(key_averages):\n",
    "                    print(f\"Event {i + 1} name: {event.key}\")\n",
    "                    attributes = [attr for attr in dir(event) if not attr.startswith(\"_\") and not callable(getattr(event, attr))]\n",
    "                    for attr in attributes:\n",
    "                        print(f\"  {attr}: {getattr(event, attr)}\")\n",
    "                    print(\"-\" * 50)  # Separator between events\n",
    "            # helper_list_events()\n",
    "                \n",
    "            profiler_data = []\n",
    "            \n",
    "            if log_to_tensorboard:\n",
    "                writer = SummaryWriter(log_dir=log_dir) \n",
    "                \n",
    "            # Usually collapsed \n",
    "            for event in key_averages:\n",
    "                if not event.key == \"[memory]\":\n",
    "                    cpu_children_time = event.cpu_time_total - event.self_cpu_time_total\n",
    "                    cuda_children_time = event.device_time_total - event.self_device_time_total\n",
    "                    \n",
    "                    event_data = {\n",
    "                        \"Name\": event.key,\n",
    "                        \"Count\": event.count,\n",
    "                        # Timing attributes\n",
    "                        \"CPU time op only\": event.self_cpu_time_total,\n",
    "                        \"CPU time total (+children)\": event.cpu_time_total,\n",
    "                        \"CPU children time\": cpu_children_time,\n",
    "\t\t\t\t\t\t\"CUDA time op only\": event.self_device_time_total,\n",
    "\t\t\t\t\t\t\"CUDA time total (+children)\": event.device_time_total,\n",
    "\t\t\t\t\t\t\"CUDA children time\": cuda_children_time,\t\n",
    "\t\t\t\t\t\t# Memory attributes\n",
    "\t\t\t\t\t\t\"CPU memory usage (+children)\": event.cpu_memory_usage,\n",
    "\t\t\t\t\t\t\"CPU memory usage op only\": event.self_cpu_memory_usage,\n",
    "\t\t\t\t\t\t\"CUDA memory usage (+children)\": event.device_memory_usage,\n",
    "\t\t\t\t\t\t\"CUDA memory usage op only\": event.self_device_memory_usage,\n",
    "\t\t\t\t\t\t# Performance\n",
    "\t\t\t\t\t\t\"Flops\": event.flops,\t\n",
    "\t\t\t\t\t\t\"Is Async\": event.is_async,\n",
    "\t\t\t\t\t\t\"Input Shapes\": event.input_shapes,\n",
    "\t\t\t\t\t\t\"Stack\": event.stack\n",
    "\t\t\t\t\t}\n",
    "                    \n",
    "                    profiler_data.append(event_data)\n",
    "                    \n",
    "                    # Log metrics to TensorBoard\n",
    "                    if log_to_tensorboard:\n",
    "                        writer.add_scalar(\"Performance/CPU_time_op_only\", event.self_cpu_time_total, global_step=event.count)\n",
    "                        writer.add_scalar(\"Performance/CPU_time_total\", event.cpu_time_total, global_step=event.count)\n",
    "                        writer.add_scalar(\"Performance/CPU_children_time\", cpu_children_time, global_step=event.count)\n",
    "                        writer.add_scalar(\"Performance/CUDA_time_op_only\", event.self_device_time_total, global_step=event.count)\n",
    "                        writer.add_scalar(\"Performance/CUDA_time_total\", event.device_time_total, global_step=event.count)\n",
    "                        writer.add_scalar(\"Performance/CUDA_children_time\", cuda_children_time, global_step=event.count)\n",
    "                        writer.add_scalar(\"Performance/FLOPS\", event.flops, global_step=event.count)\n",
    "                        writer.add_scalar(\"Memory/CPU_memory_usage_children\", event.cpu_memory_usage, global_step=event.count)\n",
    "                        writer.add_scalar(\"Memory/CUDA_memory_usage_children\", event.device_memory_usage, global_step=event.count)\n",
    "                        \n",
    "            df = pd.DataFrame(profiler_data)\n",
    "\t\n",
    "            if create_csv_file:\n",
    "                df.to_csv(f\"./operations/{self.model_name}_profiler_data.csv\", index=False)\n",
    "                \n",
    "            if log_to_tensorboard:\n",
    "                writer.close()\n",
    "                \n",
    "            if plot_events:\n",
    "                numeric_columns = [\n",
    "\t\t\t\t\t\"CPU time op only\", \"CPU time total (+children)\", \"CPU children time\",\n",
    "\t\t\t\t\t\"CUDA time op only\", \"CUDA time total (+children)\", \"CUDA children time\",\n",
    "\t\t\t\t\t\"CPU memory usage (+children)\", \"CPU memory usage op only\",\n",
    "\t\t\t\t\t\"CUDA memory usage (+children)\", \"CUDA memory usage op only\", \"Flops\"\n",
    "\t\t\t\t]\n",
    "                df[numeric_columns] = df[numeric_columns].apply(pd.to_numeric, errors='coerce')\n",
    "                df = df.dropna()\n",
    "\n",
    "\t\t\t\t# Usually collapsed \n",
    "                def helper_plot_events(df=df):\n",
    "                    # CPU vs CUDA Time (Operation Only)\n",
    "                    plt.figure(figsize=(14, 6))\n",
    "                    df_melted = df.melt(\n",
    "\t\t\t\t\t\tid_vars=[\"Name\"], \n",
    "\t\t\t\t\t\tvalue_vars=[\"CPU time op only\", \"CUDA time op only\"],\n",
    "\t\t\t\t\t\tvar_name=\"Type\", \n",
    "\t\t\t\t\t\tvalue_name=\"Time (us)\"\n",
    "\t\t\t\t\t)\n",
    "                    sns.barplot(data=df_melted, x=\"Name\", y=\"Time (us)\", hue=\"Type\")\n",
    "                    plt.xticks(rotation=90)\n",
    "                    plt.title(\"CPU vs CUDA Time (Operation Only)\")\n",
    "                    plt.show()\n",
    "\t\t\t\t\t\n",
    "                helper_plot_events()  \n",
    "            \n",
    "            return df\n",
    "        \n",
    "    def analyze_layers(self, create_csv=False) -> Optional[pd.DataFrame]:\n",
    "        \"\"\"Uses a recursive function to extract layer information from the model.\"\"\"\n",
    "        layers_data = []\n",
    "    \n",
    "        def extract_layer_info(name, module, parent_name=\"\") -> None:\n",
    "\t\t\t# Define layer_info here and update it dynamically\t\n",
    "            layer_info = {\n",
    "\t\t\t\t\"Name\": f\"{parent_name}.{name}\" if parent_name else name,\n",
    "\t\t\t\t\"Type\": module.__class__.__name__,\n",
    "\t\t\t}\n",
    "                        \n",
    "            layers_data.append(layer_info)\n",
    "            \n",
    "        def recurse_layers(module, parent_name=\"\") -> None:\n",
    "            for name, child in module.named_children():\n",
    "                extract_layer_info(name, child, parent_name)\n",
    "                recurse_layers(child, parent_name=f\"{parent_name}.{name}\" if parent_name else name)\n",
    "\n",
    "        recurse_layers(self.model)\n",
    "\n",
    "        df = pd.DataFrame(layers_data)\n",
    "        if create_csv:\n",
    "            df.to_csv(f\"./layers/{self.model_name}_layers.csv\", index=False)\n",
    "\n",
    "        return df\n",
    "    \n",
    "    \n",
    "    def measure_inference_time(self, mode='single', num_warmup_runs=10, num_measurement_runs=10, batch_size=None) -> Optional[float]:\n",
    "        self.model.eval()\n",
    "        input_size = self.model.default_cfg.get('input_size', (3, 224, 224))\n",
    "\n",
    "        if mode == 'single':\n",
    "            # Single image inference\n",
    "            batch_size = 1\n",
    "            print(\"Measuring inference time for single image...\")\n",
    "        elif mode == 'batch':\n",
    "            # Batch inference\n",
    "            if batch_size is None:\n",
    "                batch_size = 512  # Default batch size from ViT paper\n",
    "            print(f\"Measuring inference time for batch size {batch_size}...\")\n",
    "        else:\n",
    "            raise ValueError(\"Mode must be 'single' or 'batch'.\")\n",
    "\n",
    "        # Prepare input tensor\n",
    "        sample_input = torch.randn(batch_size, *input_size).to(self.device)\n",
    "\n",
    "        # Warm-up runs\n",
    "        with torch.no_grad():\n",
    "            for _ in range(num_warmup_runs):\n",
    "                _ = self.model(sample_input)\n",
    "            # Ensure all operations are complete\n",
    "            if self.device.type == 'cuda':\n",
    "                torch.cuda.synchronize()\n",
    "\n",
    "        # Measurement runs\n",
    "        inference_times = []\n",
    "        with torch.no_grad():\n",
    "            for _ in range(num_measurement_runs):\n",
    "                start_time = time.time()\n",
    "                _ = self.model(sample_input)\n",
    "                if self.device.type == 'cuda':\n",
    "                    torch.cuda.synchronize()\n",
    "                end_time = time.time()\n",
    "                inference_time = (end_time - start_time) * 1000  # Convert to milliseconds\n",
    "                inference_times.append(inference_time)\n",
    "\n",
    "        avg_inference_time_ms = sum(inference_times) / len(inference_times)\n",
    "        print(f\"Average Inference Time: {avg_inference_time_ms:.2f} ms\")\n",
    "\n",
    "        # return avg_inference_time_ms\n",
    "    \n",
    "    def analyze_performance(self, create_csv=False) -> Optional[pd.DataFrame]:\n",
    "        \"\"\"\n",
    "        Analyze the performance of each layer in the model using forward hooks,\n",
    "        identify bottlenecks, and optionally save the data to a CSV file.\n",
    "\t\t\"\"\"\n",
    "\n",
    "\t\t# Dictionary to store timing information\n",
    "        timings = {}\n",
    "\t\t\n",
    "        def register_hooks(module, name):\n",
    "            \"\"\"\n",
    "\t\t\tRegisters forward hooks to measure the execution time of each module.\n",
    "\t\t\t\"\"\"\n",
    "            def pre_forward_hook(module, input):\n",
    "                module.start_time = time.perf_counter()\n",
    "\t\t\t\t\n",
    "            def post_forward_hook(module, input, output):\n",
    "                elapsed_time = (time.perf_counter() - module.start_time) * 1000  # Convert to milliseconds\n",
    "                if name in timings:\n",
    "                    timings[name][\"Total Time (ms)\"] += elapsed_time\n",
    "                    timings[name][\"Calls\"] += 1\n",
    "                else:\n",
    "                    timings[name] = {\"Total Time (ms)\": elapsed_time, \"Calls\": 1}\n",
    "\t\t\t\t\t\n",
    "            module.register_forward_pre_hook(pre_forward_hook)\n",
    "            module.register_forward_hook(post_forward_hook)\n",
    "\t\t\n",
    "\t\t# Register hooks for all submodules\n",
    "        for name, module in self.model.named_modules():\n",
    "            register_hooks(module, name)\n",
    "\t\t\n",
    "\t\t# Prepare a sample input tensor\n",
    "        input_size = self.model.default_cfg.get('input_size', (3, 224, 224))\n",
    "        sample_input = torch.randn(1, *input_size).to(self.device)\n",
    "\t\t\n",
    "\t\t# Run inference to trigger the hooks\n",
    "        self.inference_one(sample_input)\n",
    "\t\t\n",
    "\t\t# Remove hooks to avoid side effects\n",
    "        for module in self.model.modules():\n",
    "            module._forward_pre_hooks.clear()\n",
    "            module._forward_hooks.clear()\n",
    "\t\t\n",
    "\t\t# Compile timing data into a DataFrame\n",
    "        data = []\n",
    "        for name, info in timings.items():\n",
    "            data.append({\n",
    "\t\t\t\t\"Layer Name\": name,\n",
    "\t\t\t\t\"Total Time (ms)\": info[\"Total Time (ms)\"],\n",
    "\t\t\t\t\"Calls\": info[\"Calls\"],\n",
    "\t\t\t\t\"Average Time per Call (ms)\": info[\"Total Time (ms)\"] / info[\"Calls\"]\n",
    "\t\t\t})\n",
    "\t\t\n",
    "        df = pd.DataFrame(data)\n",
    "        df = df.sort_values(by=\"Total Time (ms)\", ascending=False)\n",
    "\t\t\n",
    "        if create_csv:\n",
    "            df.to_csv(f\"./performance/{self.model_name}_layer_timings.csv\", index=False)\n",
    "\t\t\n",
    "        print(\"Top bottlenecks:\")\n",
    "        print(df.head(10))\n",
    "\t\t\n",
    "        return df\n",
    "\t\t\t\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        # \"\"\"\n",
    "        # Analyzes the performance of each layer in the model.\n",
    "\n",
    "        # Parameters:\n",
    "        # - input_size (tuple): Input size excluding batch dimension, e.g., (3, 224, 224).\n",
    "        # - create_csv (bool): Whether to save the results to a CSV file.\n",
    "\n",
    "        # Returns:\n",
    "        # - df (pd.DataFrame): DataFrame containing per-layer performance metrics.\n",
    "        # \"\"\"\n",
    "        # print(\"Analyzing per-layer performance...\")\n",
    "\n",
    "        # # Use default input size if not provided\n",
    "        # if input_size is None:\n",
    "        #     input_size = self.model.default_cfg.get('input_size', (3, 224, 224))\n",
    "\n",
    "        # # Prepare a sample input\n",
    "        # sample_input = torch.randn(1, *input_size).to(self.device)\n",
    "\n",
    "        # # Dictionary to store metrics\n",
    "        # layer_metrics = {}\n",
    "\n",
    "        # # Function to register hooks\n",
    "        # def register_hooks(module, name):\n",
    "\n",
    "        #     def pre_forward_hook(module, input):\n",
    "        #         module.__start_time = time.time()\n",
    "\n",
    "        #     def forward_hook(module, input, output):\n",
    "        #         elapsed_time = (time.time() - module.__start_time) * 1000  # Convert to milliseconds\n",
    "        #         layer_metrics[name]['Execution Time (ms)'] = elapsed_time\n",
    "\n",
    "        #     # Only register hooks to leaf modules\n",
    "        #     if len(list(module.children())) == 0:\n",
    "        #         layer_metrics[name] = {\n",
    "        #             'Type': module.__class__.__name__,\n",
    "        #             'Parameters': sum(p.numel() for p in module.parameters() if p.requires_grad),\n",
    "        #             'MACs': 0,\n",
    "        #             'Execution Time (ms)': 0,\n",
    "        #             'Memory Usage (MB)': 0,\n",
    "        #         }\n",
    "        #         module.register_forward_pre_hook(pre_forward_hook)\n",
    "        #         module.register_forward_hook(forward_hook)\n",
    "\n",
    "        # # Register hooks\n",
    "        # for name, module in self.model.named_modules():\n",
    "        #     register_hooks(module, name)\n",
    "\n",
    "        # # Use PyTorch Profiler to collect detailed metrics\n",
    "        # with profile(activities=[ProfilerActivity.CPU, ProfilerActivity.CUDA],\n",
    "        #             record_shapes=True,\n",
    "        #             profile_memory=True,\n",
    "        #             with_stack=True) as prof:\n",
    "        #     with torch.no_grad():\n",
    "        #         self.model(sample_input)\n",
    "\n",
    "        # # Remove hooks\n",
    "        # for module in self.model.modules():\n",
    "        #     module._backward_hooks = {}\n",
    "        #     module._forward_hooks = {}\n",
    "        #     module._forward_pre_hooks = {}\n",
    "\n",
    "        # # Process profiler events\n",
    "        # prof_data = prof.key_averages(group_by_input_shape=True)\n",
    "\n",
    "        # for event in prof_data:\n",
    "        #     module_name = event.key\n",
    "        #     if module_name in layer_metrics:\n",
    "        #         layer_metrics[module_name]['MACs'] = event.flops  # Number of FLOPs\n",
    "        #         layer_metrics[module_name]['Memory Usage (MB)'] = event.self_cpu_memory_usage / (1024 ** 2)  # Convert to MB\n",
    "\n",
    "        # # Convert the metrics dictionary to a DataFrame\n",
    "        # df = pd.DataFrame.from_dict(layer_metrics, orient='index')\n",
    "        # df.reset_index(inplace=True)\n",
    "        # df.rename(columns={'index': 'Name'}, inplace=True)\n",
    "\n",
    "        # # Sort DataFrame by Execution Time\n",
    "        # df.sort_values(by='Execution Time (ms)', ascending=False, inplace=True)\n",
    "\n",
    "        # if create_csv:\n",
    "        #     df.to_csv(f\"./performance/{self.model_name}_performance.csv\", index=False)\n",
    "\n",
    "        # print(\"Per-layer performance analysis completed.\")\n",
    "        # return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def del_logs():\n",
    "    for file in os.listdir('./logs'):\n",
    "        os.remove(os.path.join('./logs', file))\n",
    "def del_operations():\n",
    "    for file in os.listdir('./operations'):\n",
    "        os.remove(os.path.join('./operations', file))\n",
    "def del_layers():\n",
    "    for file in os.listdir('./layers'):\n",
    "        os.remove(os.path.join('./layers', file))\n",
    "def del_performance():\n",
    "    for file in os.listdir('./performance'):\n",
    "        os.remove(os.path.join('./performance', file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "del_logs()\n",
    "del_operations()\n",
    "del_layers()\n",
    "del_performance()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Model device: cuda:0\n",
      "Input tensor device: cuda:0\n",
      "All model parameters are on the GPU\n",
      "Initialization done\n",
      "------------------------------------------------------------------------\n",
      "Measuring inference time for single image...\n",
      "Average Inference Time: 21.98 ms\n",
      "Model device: cuda:0\n",
      "Input tensor device: cuda:0\n",
      "Top bottlenecks:\n",
      "    Layer Name  Total Time (ms)  Calls  Average Time per Call (ms)\n",
      "251                     10.9134      1                     10.9134\n",
      "246     blocks          10.1605      1                     10.1605\n",
      "25    blocks.0           1.4680      1                      1.4680\n",
      "165   blocks.7           0.9619      1                      0.9619\n",
      "145   blocks.6           0.8989      1                      0.8989\n",
      "125   blocks.5           0.8711      1                      0.8711\n",
      "45    blocks.1           0.8400      1                      0.8400\n",
      "185   blocks.8           0.7501      1                      0.7501\n",
      "205   blocks.9           0.7312      1                      0.7312\n",
      "105   blocks.4           0.7267      1                      0.7267\n"
     ]
    }
   ],
   "source": [
    "analyzer = Analyzer(model_name, device=\"cuda\")\n",
    "input_tensor = torch.randn(1, 3, 224, 224)\n",
    "analyzer.start_profiler(create_logfile=False)  # Creates logs of each operation\n",
    "analyzer.inference_one(input_tensor)\n",
    "analyzer.stop_profiler()\n",
    "analyzer.is_cuda_initialized(logs=False)\n",
    "print(\"Initialization done\")\n",
    "print(\"------------------------------------------------------------------------\")\n",
    "analyzer.list_events(show_key_averages=False, list_all=False)\n",
    "\n",
    "events_df = analyzer.event_handler(create_csv_file=False, log_to_tensorboard=False, plot_events=False)\n",
    "layers_df = analyzer.analyze_layers(create_csv=False)\n",
    "\n",
    "analyzer.measure_inference_time(mode='single', num_warmup_runs=10, num_measurement_runs=10)\n",
    "\n",
    "performance_df = analyzer.analyze_performance(create_csv=True) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
